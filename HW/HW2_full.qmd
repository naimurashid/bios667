---
title: "BIOS 667 — Homework 4 (Student Starter, Final Version)"
subtitle: "Linear and Generalized Linear Models (Chs. 8–11)"
author: "REPLACE THIS STRING WITH THE LAST 5 DIGITS OF YOUR PID FOR ANONYMITY"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: false
    code-fold: show
    theme: flatly
execute:
  warning: false
  message: false
editor: visual
---

```{r}
#| label: setup
#| echo: true
# Load required packages
suppressPackageStartupMessages({
  library(tidyverse)
  library(lme4)      # for lmer/glmer
  library(nlme)      # for lme
  library(MASS)      # for polr, glm.nb
  library(broom)     # for tidy() outputs
  library(geepack)   # for GEE (if needed for comparison)
})

# Ensure reproducibility
seed <- 22222  # replace with your last 5 PID digits
stopifnot(seed >= 10000 & seed <= 99999)
set.seed(seed)

# Set options for clean output
options(contrasts = c("contr.treatment", "contr.poly"))
knitr::opts_chunk$set(fig.width = 6, fig.height = 4, dpi = 120)
```

---

## 0. Data Setup

> Each student has a unique simulated dataset based on their PID seed.
> The dataset includes continuous, binary, count, and ordinal outcomes.

```{r}
#| label: data-simulation
#| echo: true
message("Simulating dataset...")
N <- 120; Tt <- 5
id <- rep(1:N, each = Tt)
time <- rep(0:(Tt-1), N)
trt <- rep(rbinom(N, 1, 0.5), each = Tt)

# Random intercepts/slopes
b0 <- rep(rnorm(N, 0, 1.2), each = Tt)
b1 <- rep(rnorm(N, 0, 0.4), each = Tt)

# AR(1) errors
rho <- 0.5; sd_eps <- 1.0
eps <- unlist(lapply(1:N, function(i) {
  as.numeric(arima.sim(list(ar = rho), n = Tt, sd = sd_eps))
}))

# Continuous response (with interaction)
y <- 10 + 0.6*time + 1.0*trt + 0.5*trt*time + b0 + b1*time + eps

# Binary outcome (main effects only for simplicity)
lp_bin <- -1 + 0.2*time + 0.6*trt
p_bin  <- plogis(lp_bin)
y_bin  <- rbinom(N*Tt, 1, p_bin)

# Count outcome (main effects only)
mu_count <- exp(1.2 + 0.15*time + 0.25*trt)
y_count  <- rpois(N*Tt, mu_count)

# Ordinal outcome (derived from y, so it also has an interaction)
cuts <- quantile(y, probs = c(.25, .5, .75))
ordinal_y <- cut(y, breaks = c(-Inf, cuts, Inf),
                 labels = c("L","M","H","VH"), ordered_result = TRUE)

dat <- tibble(
  id = factor(id),
  time = as.integer(time),
  trt = factor(trt, levels = c(0,1), labels = c("Ctl","Tx")),
  y = y,
  y_bin = as.integer(y_bin),
  y_count = as.integer(round(y_count)),
  ordinal_y = ordered(ordinal_y)
)

glimpse(dat)
summary(dat[, c("y","y_bin","y_count","ordinal_y")])
```

---

## 1) Conceptual Foundations (25 pts)

### 1.1 Model Hierarchy (10 pts)

**(WRITE):** Explain how OLS, LMM, and GLM differ in
(a) their assumptions about the mean structure, (b) their assumptions about the variance/covariance, and (c) their overall distributional assumptions.

> (Your answer should be 2–4 sentences per model, and you can use a small schematic if it helps clarify the differences).


---

### 1.2 Residuals & Diagnostics (10 pts)

**(WRITE):** Contrast **marginal** and **conditional** residuals in the context of Linear Mixed-Effects Models. For what diagnostic purpose is each type of residual most appropriate? 

---

### 1.3 Link Functions (5 pts)

**(WRITE):** Explain how the **identity**, **logit**, and **log** link functions change the interpretation of a non-intercept regression coefficient $\beta$. For each, complete the sentence: "A one-unit increase in predictor $X$ is associated with..."

---

## 2) Applied Modeling (55 pts)

### 2.1 Linear Mixed Model (15 pts)

**Prompt:** Fit a linear mixed-effects model for the continuous outcome `y`, including a random intercept and random slope for `time`. Your fixed effects should include `time`, `trt`, and their interaction.

**Tasks:**
1.  (CODE & WRITE) Fit the model using `nlme::lme()` and present the `summary()` output.
2.  (WRITE) Interpret the fixed effect coefficient for the `time:trtTx` interaction.
3.  (WRITE) Report the variance components. In your narrative, explain what the standard deviations of the random intercept and slope tell you about the between-subject heterogeneity in this dataset. Also, interpret the *sign and magnitude* of the correlation between the random effects.
4.  (CODE & WRITE) Create diagnostic plots: (a) conditional residuals vs. fitted values, and (b) a QQ plot of the conditional residuals. Comment on whether the model assumptions appear to be met.
5.  (CODE & WRITE) Create QQ plots for the random effects (intercepts and slopes). Do they appear normally distributed?

```{r}
#| label: lmm-fit
#| echo: true

# Fit model and print summary
fit_lmm <- lme(y ~ time * trt, random = ~ 1 + time | id, data = dat, method = "REML")
summary(fit_lmm)

# report variance components
VarCorr(fit_lmm)
```

*Your interpretation of the interaction, variance components, and diagnostics goes here.*

```{r}
#| label: lmm-diagnostics
#| echo: true

# obtain conditional residuals and fitted values
res_lmm <- resid(fit_lmm, type = "normalized") 
fit_lv1 <- fitted(fit_lmm, level = 1)

# plot conditional residuals vs fitted values
par(mfrow = c(1,2))
plot(fit_lv1, res_lmm, pch=19, cex=.5,
     xlab="Fitted (level 1)", ylab="Normalized Conditional Residuals")
abline(h=0,lty=2)

# make qq plot for the conditional residuals
qqnorm(res_lmm); qqline(res_lmm)
par(mfrow = c(1,1))

# create qq plots for the random effects (intercepts, and also for slopes)
re_lmm <- ranef(fit_lmm)
par(mfrow = c(1,2))
qqnorm(re_lmm[,1], main = "RE Intercepts"); qqline(re_lmm[,1])
qqnorm(re_lmm[,2], main = "RE Slopes"); qqline(re_lmm[,2])
par(mfrow = c(1,1))
```

*Your comments on the diagnostic plots go here.*

---

### 2.2 Logistic GLM (Binary) (10 pts)

Fit a logistic regression model for the binary outcome `y_bin`.

**Tasks:**
1.  (CODE & WRITE) Fit the model `y_bin ~ time * trt` and present the `summary()` output.
2.  (WRITE) Interpret the odds ratio for the `trtTx` main effect. Be very specific about the *condition* under which this odds ratio applies (i.e., the value of the `time` variable).
3.  (CODE & WRITE) Plot the deviance residuals vs. the fitted probabilities and comment on the plot.

```{r}
#| label: logit-fit
#| echo: true

# fit the model and print summary
fit_logit <- glm(y_bin ~ time * trt, family = binomial, data = dat)
summary(fit_logit)

# Report the odds ratio based on the fitted model
exp(coef(fit_logit))

```

*Your interpretation of the odds ratio goes here.*

```{r}
#| label: logit-diagnostics
#| echo: true

# plot the deviance resituations vs. the fitted probabilities
dat <- dat %>%
  mutate(logit_fitted = fitted(fit_logit),
         logit_dev_resid = residuals(fit_logit, type = "deviance"))
ggplot(dat, aes(logit_fitted, logit_dev_resid)) +
  geom_point(alpha=.4) +
  geom_hline(yintercept=0, linetype="dashed") +
  labs(x="Fitted probability", y="Deviance residual", title = "Deviance Residuals vs. Fitted (Logistic)") +
  theme_minimal()
```

*Your comments on the residual plot go here.*

---

### 2.3 Poisson vs. Quasi-Poisson (10 pts)

Model the count outcome `y_count` using both a Poisson and a Quasi-Poisson GLM.

**Tasks:**
1.  (CODE & WRITE) Fit both `y_count ~ time + trt` models and present the `tidy()` output for each.
2.  (WRITE) Compare the coefficient estimates and standard errors between the two models.
3.  (CODE & WRITE) Calculate and interpret the estimated dispersion parameter ($\hat\phi$) from the quasi-Poisson model. What does its value tell you about the appropriateness of the standard Poisson model?

```{r}
#| label: count-models
#| echo: true

# fit poisson model
fit_pois <- glm(y_count ~ time + trt, family = poisson(), data = dat)

# fit quasi-poisson model
fit_qp   <- glm(y_count ~ time + trt, family = quasipoisson(), data = dat)

# print output from tidy() on each model object
tidy(fit_pois)
tidy(fit_qp)

# report the estimated dispersion parameter from the quasi-poisson model
phi <- summary(fit_qp)$dispersion
cat("Estimated dispersion (phi) =", round(phi,2), "\n")
```

*Your comparison of the coefficient estimates/SEs as well as the interpretation of the dispersion parameter go here.*

---

### 2.4 Ordinal Response (Proportional Odds) (10 pts)

Fit a proportional odds logistic regression model for the `ordinal_y` outcome.

**Tasks:**
1.  (CODE & WRITE) Fit the model `ordinal_y ~ time * trt` using `MASS::polr()` and present the `summary()`.
2.  (WRITE) Interpret the odds ratio for the `trtTx` treatment effect. Specifically, explain how treatment is associated with the odds of a subject being in a *lower vs. higher* category on the `ordinal_y` scale.
3.  (WRITE) In your own words, what is the "proportional odds" assumption?
4.  (CODE & WRITE) Create and interpret the empirical cumulative logit plot to visually check the proportional odds assumption for the `time` variable.

```{r}
#| label: ordinal-fit
#| echo: true

# fit the nodel and present the summary
fit_polr <- polr(ordinal_y ~ time * trt, data = dat, Hess = TRUE)
summary(fit_polr)
exp(coef(fit_polr))
```

*Your interpretation of the odds ratio goes here.*

```{r}
#| label: ordinal-diagnostics
#| echo: true

dat_ord_check <- dat %>%
  mutate(
    le_L = as.numeric(ordinal_y <= "L"),
    le_M = as.numeric(ordinal_y <= "M"),
    le_H = as.numeric(ordinal_y <= "H")
  ) %>%

  pivot_longer(starts_with("le_"), names_to = "cutpoint", values_to = "indicator")


ggplot(dat_ord_check, aes(x = time, y = indicator)) +
  stat_summary(fun.data = "mean_cl_boot", geom = "line") +
  stat_summary(fun.data = "mean_cl_boot", geom = "point") +
  scale_y_continuous(trans = "logit", breaks = c(0.1, 0.25, 0.5, 0.75, 0.9)) +
  facet_grid(trt ~ cutpoint) +
  labs(title = "Empirical Cumulative Logits vs. Time",
       subtitle = "Parallel lines support the Proportional Odds assumption",
       y = "Logit(P(Y <= k))") +
  theme_bw()
```

*Your interpretation of the PO assumption goes here.*

## 3) Peer Review (15 pts)

After the HW has been turned in, review two classmates’ submissions (≈ 100 words each). You do not need to provide a numeric score, but instead provide comments that address:
- Model specification accuracy  
- Clarity of interpretation  
- Diagnostic reasoning  
- Organization and visuals

You will be randomly assigned your peer assessments in Canvas.   Provide your comments in canvas as well as a brief overall summary sentence for each peer.  Please be thorough and constructive. 

---

## 4) Formatting & Reproducibility (5 pts)

- Knit runs without error  
- Figures / tables labeled and referenced  
- Seed set at top  
- File readable and organized  

---

## Reminders

- `id` must be a factor  
- `polr()` requires an ordered response  
- Do not compare AIC for quasi-Poisson  
- Logistic GLM requires a binary outcome  
- Check overdispersion for counts  

---
